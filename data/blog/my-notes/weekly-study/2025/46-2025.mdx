---
title: 2025-第四十六周
date: '2025-11-04'
tags: ['WEEKLY-2025']
draft: false
summary: ''
---

`该周报主要为各个地方内容的汇总整理`

<TOCInlineWithSticky toc={props.toc} />

## 技术

### [JavaScript 中的错误链：使用 Error.cause 实现更清晰的调试](https://allthingssmitty.com/2025/11/10/error-chaining-in-javascript-cleaner-debugging-with-error-cause/)

本文介绍了 JavaScript 中 `Error.cause` 属性的用途和优势，它解决了传统错误处理中原始错误信息丢失的问题，并提供了标准化的错误链管理方法。

- 🎯 **传统错误处理的问题**：通过字符串拼接包装错误会导致原始堆栈跟踪和错误类型丢失，使得追踪根因困难。
- 🆕 **Error.cause 的引入**：ES2022 新增的 `cause` 参数允许在抛出新错误时保留原始错误，便于访问完整的错误链。
- ⚙️ **实际应用示例**：演示了如何在函数中捕获解析错误，并使用 `cause` 属性包装和传递原始错误，保持错误类型和堆栈信息。
- 🔧 **自定义错误类支持**：可以在自定义错误类（如 `DatabaseError`）中通过构造函数传递 `cause`，确保错误链的完整性。
- 🧪 **测试断言改进**：错误链使得测试更加清晰和健壮，可以直接断言深层原因错误（如 `ValidationError`）。
- ⚠️ **注意事项与最佳实践**：默认日志不会自动显示 `cause` 链，需手动记录；避免过度链式包装，以免增加调试复杂度。
- 🔄 **递归记录错误链**：提供了辅助函数来安全地遍历和记录完整的错误链，包括堆栈跟踪，适用于多层系统调试。
- 🌐 **跨层错误链示例**：展示了从数据库连接超时到服务不可用的多层错误包装，输出结构化的错误链信息。
- ✅ **环境支持**：所有现代浏览器（Chrome 93+、Firefox 91+ 等）和 Node.js 16.9+ 均支持 `cause` 属性。
- 💡 **TypeScript 配置**：使用 ES2022 作为编译目标（`"target": "es2022"`）以启用 `cause` 属性的类型支持。

### [自学前端开发者的编程原则](https://piccalil.li/blog/programming-principles-for-self-taught-front-end-developers/)

作者作为非科班出身的前端开发者，分享 20 年经验中真正实用的编程原则，强调在编写代码时直接可操作的准则而非抽象理论。

- 🎯 **三法则**：相同代码重复三次后再重构，避免过度设计
- ⚡ **先实现、再优化、后提速**：按优先级确保代码功能正确性
- 🧩 **幂等性**：保证函数相同输入始终产生相同结果
- 🔧 **单一职责**：每个函数/模块只负责一个明确功能
- 📐 **单一抽象层级**：函数内所有操作保持相同细节层次
- 🌱 **渐进复杂化**：从可工作的简单系统逐步演化复杂系统
- 🧠 **可读性优先**：代码应易于理解而非一味追求性能

### [遵循 CQRS 模式构建 NestJS 应用程序](https://www.telerik.com/blogs/building-nestjs-applications-following-the-cqrs-model)

本文介绍了如何使用 NestJS 框架构建遵循 CQRS（命令查询职责分离）模式的服务器端应用，通过创建投票应用演示了 CQRS 的核心概念和实现方法。

- 🏗️ CQRS 模式将数据读取（查询）和写入（命令）分离，通过事件驱动架构实现业务逻辑解耦
- ⚖️ 与 CRUD 架构相比，CQRS 更适合大型复杂应用，但会增加代码量和学习成本
- 🔧 使用@nestjs/cqrs 模块实现 CQRS 模式，包含查询总线、命令总线和事件总线
- 📝 演示了创建投票应用的完整流程：设置模块、定义查询、命令和事件处理器
- 🎯 查询处理器负责数据读取，命令处理器处理状态变更，事件处理器处理异步任务
- 🔄 通过 Saga 模式实现复杂的事件响应链，将事件映射到后续命令
- 💡 展示了直接与事件总线交互和通过 AggregateRoot 间接交互两种事件发布方式
- 🚀 CQRS 结合领域驱动设计能更好地模拟真实业务过程，提高系统可扩展性

### [Node.js 安全最佳实践](https://nodejs.org/en/learn/getting-started/security-best-practices)

本文档旨在扩展 Node.js 应用的威胁模型并提供全面的安全防护指南，涵盖最佳实践、攻击原理及第三方依赖管理。

- 🛡️ **HTTP 服务拒绝服务防护**：通过反向代理、超时配置和连接数限制缓解 Slowloris 等攻击
- 🔒 **调试端口安全**：生产环境禁用 Node.js 调试端口，防止 DNS 重绑定攻击
- 📁 **敏感信息保护**：使用.npmignore 和.gitignore 控制发布内容，发布前执行 dry-run 检查
- 🔄 **HTTP 请求走私防御**：禁用不安全解析器，配置前端服务器规范化请求
- ⏱️ **时序攻击防护**：采用 crypto.timingSafeEqual 进行密码比较，避免敏感操作时间差
- 📦 **第三方模块风险控制**：锁定依赖版本、使用安全扫描工具、禁用自动脚本执行
- 🧩 **原型污染防护**：冻结原型对象、禁用**proto**属性、使用无原型对象创建
- 🗂️ **模块加载安全**：通过完整性校验策略机制防止恶意模块加载
- ⚠️ **实验功能限制**：生产环境避免使用实验性功能，确保系统稳定性
- 🏅 **开源安全实践**：采用 OpenSSF 评分卡和最佳实践徽章提升项目安全等级

## 工具

### [Yuxi-Know](https://github.com/xerrors/Yuxi-Know)

语析（Yuxi-Know）是一个基于大模型的知识库与知识图谱智能体开发平台，集成了 RAG 技术、知识图谱和工具调用能力。项目采用 LangGraph v1 + Vue.js + FastAPI + LightRAG 架构，提供全套智能体开发套件，并支持 Docker 部署与多模型扩展。

- 🚀 **核心功能**：融合 RAG 知识库与知识图谱技术，支持智能体开发、工具调用及联网检索。
- 🛠️ **技术栈**：基于 LangChain/LangGraph v1、Vue、FastAPI、Neo4j 等主流框架与工具。
- 📦 **开源协议**：采用 MIT 许可证，允许自由使用与二次开发。
- 🔄 **最新动态**：v0.3 版本适配 LangGraph v1 特性，升级文档解析并优化智能体开发流程。
- 🌟 **项目热度**：GitHub 获 2.4k 星标、302 分叉，活跃社区持续贡献。
- 📚 **生态支持**：提供详细文档、视频演示及 Docker 部署指南，覆盖从开发到部署的全流程。

### [mcporter](https://github.com/steipete/mcporter)

MCPorter 是一个用于 Model Context Protocol (MCP) 的 TypeScript 运行时、CLI 和代码生成工具包。它能够自动发现系统中已配置的 MCP 服务器，直接调用它们，在 TypeScript 中组合更丰富的自动化流程，并在需要共享工具时生成单一用途的 CLI。

- 🚀 **零配置发现**: 自动加载配置并合并来自 Cursor、Claude 等编辑器的 MCP 服务器导入。
- 🛠️ **一键 CLI 生成**: 将任何 MCP 服务器定义转换为可直接运行的命令行工具。
- 📝 **类型化工具客户端**: 生成强类型的 TypeScript 接口或客户端包装器。
- 🔗 **友好可组合 API**: 提供符合人体工程学的代理方法和结果处理助手。
- 🔐 **OAuth 和 stdio 优化**: 内置 OAuth 缓存、日志跟踪和 stdio 包装器。
- 🌐 **临时连接**: 无需修改配置即可直接指向任何 MCP 端点进行调用。

- 📋 **列出 MCP 服务器**: 使用 `npx mcporter list` 查看已配置的服务器及其工具。
- 📞 **调用 MCP 工具**: 支持多种调用语法，如 `npx mcporter call linear.create_comment issueId:ENG-123 body:'Looks good!'`。
- 🔑 **OAuth 认证**: 对受保护的服务器运行 `npx mcporter auth <server>` 完成登录。
- 🖥️ **守护进程管理**: 使用 `mcporter daemon` 子命令管理状态化 stdio 服务器的生命周期。
- ⚙️ **配置管理**: 通过 `mcporter config` 命令交互式地管理项目 MCP 配置。
- 📦 **生成独立 CLI**: 使用 `npx mcporter generate-cli` 将服务器定义打包为可分享的 CLI 工具。
- 📄 **生成类型化客户端**: 使用 `npx mcporter emit-ts` 生成 `.d.ts` 接口或客户端包装器代码。

### [Hashbrown：面向生成式 UI 的 TypeScript 框架](https://hashbrown.dev/)

Hashbrown 是一个开源框架，用于构建由语言模型驱动的交互界面，帮助开发者创建多语言、无障碍且愉悦的应用程序。

- 🧩 生成式用户界面：通过 LLM 动态渲染 React/Angular 组件，保持品牌一致性和生产就绪性
- 🔧 工具调用：在浏览器中运行自定义工具，直接访问应用服务和状态
- 📊 结构化数据：使用 Skillet 模式语言从 LLM 获取类型安全的结构化输出
- 🌊 流式响应：基于 Web 标准实时流式传输 LLM 生成结果
- ☁️ 供应商无关：支持 OpenAI、Google Gemini 等多平台，即将兼容 AWS Bedrock 和 Anthropic
- ⚡ JavaScript 运行时：通过 WebAssembly 执行 AI 生成代码，动态构建服务
- 🔗 模型上下文协议：通过 MCP 客户端连接企业系统和自定义工作流
- 🎤 语音交互：集成语音转文本和文本转语音模型构建对话式界面
- 📸 图像分析：通过设备摄像头扫描文件并转换为结构化数据

### [acemir/CSSOM：使用纯JavaScript实现的CSS对象模型，同时也是一个CSS解析器。](https://github.com/acemir/CSSOM)

一个用纯 JavaScript 实现的 CSS 对象模型 (CSSOM) 库，同时也是一个 CSS 解析器。

- 🎯 纯 JavaScript 实现的 CSS 解析器和 CSS 对象模型
- 📦 支持 Node.js 和浏览器环境，可通过 npm 安装@acemir/cssom
- ⚠️ 不适用于 CSS 代码压缩或格式转换，会覆盖重复属性
- 🌐 兼容 Chrome 6+、Safari 5+、Firefox 3.6+、Opera 10.63+
- 🚫 在 IE9 以下版本无法正常工作
- 🔧 提供构建工具生成单文件版本
- 🧪 包含完整的测试套件
- 📄 采用 MIT 开源许可证
- ⭐ GitHub 上有 12 个星标和 1 个分支

### [privatenumber/tasuku: ✅ 任务 — Node.js 极简任务可视化工具](https://github.com/privatenumber/tasuku)

一个名为 Tasuku 的极简 Node.js 任务可视化工具，用于在终端中清晰展示任务执行状态。

- 📦 轻量级 Node.js 任务运行器，支持动态状态显示
- 🎯 可并行执行和嵌套任务，具有类型安全特性
- 🔄 提供任务列表视图，支持标题动态更新
- 📊 包含五种任务状态：待处理◽️、加载中🔅、警告⚠️、错误❌、成功✅
- 🏗️ 无侵入式设计，可在代码任意位置调用
- 📝 支持任务分组和并发控制，最高效利用资源
- 🛠️ 提供丰富的 API：设置状态、输出、警告和错误处理
- 🌐 灵感来源于 listr 和 ink，但更加灵活轻量

### [ebook-mcp](https://github.com/onebirdrocks/ebook-mcp)

Ebook-MCP 是一个基于模型上下文协议（MCP）的强大电子书处理服务器，为 LLM 应用与电子书处理能力之间提供了标准化的 API 集成。目前支持 EPUB 和 PDF 格式，能够通过自然语言对话实现智能图书馆管理、交互式阅读体验、主动学习支持和内容导航。

- 📚 **智能图书馆管理**：可通过自然语言查询，如“显示我下载文件夹中的所有 EPUB 文件”或“在我的图书馆中查找关于 GenAI 的书籍”。
- 💬 **交互式阅读体验**：支持与书籍进行自然对话，例如请求书籍简介、查询章节内容或总结关键知识点。
- 🧠 **主动学习支持**：通过 AI 互动增强学习效果，如基于书籍内容创建测验、解释概念差异或提供实践练习。
- 🧭 **内容导航**：使用自然语言快速定位书籍内容，例如查找讨论特定主题的所有章节或跳转到相关部分。
- ⚙️ **技术特性**：支持 EPUB 和 PDF 格式的元数据提取、目录提取、章节内容提取（支持 Markdown 输出）及批量处理。
- 🛠️ **集成与使用**：可集成到现代 AI 驱动的 IDE（如 Cursor 和 Claude），提供开发和生产两种运行模式，并配有完整的 API 参考。

## 更新

### [Bun v1.3.2 | Bun 博客](https://bun.com/blog/bun-v1.3.2)

Bun 1.3.2 版本修复了 287 个问题，主要更新包括恢复提升安装为默认方式、引入配置版本锁定机制、新增 CPU 性能分析功能、优化依赖安装速度，并改进了 WebSocket、测试框架和 Docker 支持。

- 🚀 安装方式：支持 curl/npm/powershell/scoop/brew/docker 多种安装命令
- 🔄 默认安装调整：现有项目恢复使用提升安装，新项目仍默认隔离安装
- 📌 配置版本锁定：通过 configVersion 字段避免未来版本升级时的破坏性变更
- ⚡ 性能提升：热门库安装速度优化，Next.js+Vite 项目安装提速 6 倍
- 📊 CPU 性能分析：新增--cpu-prof 标志生成 Chrome DevTools 兼容的性能分析文件
- 🧪 测试增强：bun:test 新增 onTestFinished 钩子，支持串行测试中的异步清理
- 🔌 WebSocket 改进：ServerWebSocket 新增 subscriptions 获取器便于主题管理
- 🐳 Docker 更新：官方镜像升级至 Alpine 3.22，提升安全性和兼容性
- 🔗 Git 依赖解析：改进 GitHub 简写和协议前缀的依赖解析逻辑
- 📋 依赖查看：新增 bun list 命令作为 bun pm ls 的快捷别名
- 🐛 问题修复：涵盖 Node.js 兼容性、N-API、HTTP/HTTPS、bun test、bun build 等多个领域

### [React Email 5.0 · 重发版](https://resend.com/blog/react-email-5)

React Email 5.0 正式发布，新增深色模式切换器、Tailwind 4 支持、Resend 集成及 8 个新组件，同时公布显著增长数据与升级指南。

- 🌙 深色模式切换器：全新主题系统通过多邮件客户端兼容性测试，简化邮件主题设计
- 🎨 Tailwind 4 支持：提升代码简洁度与性能，CSS 兼容性检查确保邮件渲染稳定性
- 🤝 Resend 集成：支持非技术团队成员通过可视化编辑器实时协作编辑邮件模板
- 🧩 新增 8 个组件：包含头像组件（4 个）、数据统计组件（2 个）和用户评价组件（2 个）
- 📈 生态数据增长：npm 周下载量达 92 万次（同比增长 117%），GitHub 获 1.7 万星标，182 位贡献者参与
- ⚡ 升级要求：需同步更新 react-email 与@react-email/components，并将 renderAsync 替换为 render 方法
- 🔧 环境升级：已支持 React 19.2 与 Next.js 16，详细更新记录可查阅官方变更日志

### [TanStack DB 0.5 — 查询驱动同步 | TanStack 博客](https://tanstack.com/blog/tanstack-db-0.5-query-driven-sync)

TanStack DB 0.5 版本引入了查询驱动同步功能，通过组件查询自动生成精确的 API 调用，无需自定义端点或后端修改，支持三种同步模式以适应不同数据规模，并利用差异数据流技术实现亚毫秒级客户端查询更新。

- 🚀 查询即 API：组件查询自动转换为精准 API 请求，无需额外接口开发
- 🎯 三种同步模式：即时模式（全量加载）、按需模式（查询驱动加载）、渐进模式（混合加载）
- ⚡ 差异数据流：仅重新计算变更数据，10 万行数据更新响应 < 1ms
- 🔗 智能请求优化：自动合并重复请求、增量加载、关联查询批量处理
- 🔄 无缝缓存集成：内置 TanStack Query 缓存策略，支持过期时间和垃圾回收
- 🛠️ 多后端支持：兼容 REST/GraphQL/tRPC，可逐步迁移至实时同步引擎
- 📊 渐进式增强：支持从简单 API 映射开始，逐步优化查询下推
- 🎪 实时协作支持：与 Electric 等同步引擎结合实现实时数据流
- 🧩 声明式编程：采用 React 式纯函数查询，组件声明数据需求框架处理实现

## AI

### [CodeMachine-CLI](https://github.com/moazbuilds/CodeMachine-CLI)

CodeMachine CLI 是一个本地运行的自主多智能体平台，能够将规范文件转化为生产就绪的代码。它通过协调多个 AI 智能体，支持大规模并行执行和长期工作流，显著提升开发效率。最新版本 v0.5.0 集成了 OpenCode CLI 引擎，并增强了类型安全性。

- 🚀 **自主代码生成**：CodeMachine 通过多智能体协作，将规范自动转换为完整代码库，其自身 90% 的代码由该工具生成。
- ⚙️ **多引擎支持**：兼容多种 AI 引擎（如 Codex CLI、Claude Code、OpenCode CLI 等），支持跨平台运行。
- 🔄 **并行工作流**：支持智能体分层与并行执行，可动态调整任务流程，实现高效协作。
- 📦 **快速入门**：通过 npm 全局安装后，只需添加规范文件并运行命令即可启动自动化开发流程。
- 🛠️ **生产验证**：已在 Sustaina Platform 项目中成功生成 7 个微服务、500+ 文件及 6 万行代码，验证其生产环境适用性。
- ⚡ **高效对比**：相比传统人工协调 AI 工具，CodeMachine 将开发时间从 200-300 小时缩短至 8 小时，效率提升 25-37 倍。
- 📚 **文档齐全**：提供详细的使用指南、核心概念说明及自定义工作流配置方法，方便开发者深入使用。

### [Memori](https://github.com/GibsonAI/Memori)

Memori 是一个开源的 SQL 原生内存引擎，旨在为任何 LLM 提供持久化、可查询的记忆功能。它通过简单的代码集成，支持多种 SQL 数据库和 LLM 框架，显著降低成本并避免供应商锁定。

- 🧠 **一键集成记忆功能**：仅需一行代码 `memori.enable()` 即可为 LLM 添加持久化记忆，支持 OpenAI、Anthropic 等主流框架。
- 🗃️ **SQL 原生存储**：记忆数据存储在标准 SQL 数据库（如 SQLite、PostgreSQL）中，用户完全掌控且可移植。
- 💰 **成本节约显著**：无需昂贵的向量数据库，可节省 80-90% 的成本。
- 🔍 **智能记忆管理**：支持自动实体提取、关系映射和上下文优先级排序，提升 LLM 的交互质量。
- ⚙️ **灵活配置模式**：提供 Conscious（短期工作记忆）、Auto（动态搜索）及 Combined 模式，适应不同应用场景。
- 🌐 **多框架支持**：兼容 LiteLLM、LangChain 等 100 多种模型，并通过拦截调用实现无缝集成。
- 🚀 **开源与社区驱动**：采用 Apache 2.0 许可证，鼓励社区贡献，提供详细文档和示例。
- 📈 **应用场景广泛**：适用于个人助手、多用户系统、研究助手等，支持实时交互和模式分析。

## 其他

跟常规 API 不同，MCP 作为接口有一个好处。

常规 API 是对开发者的一种承诺，发布后不能轻易改变。但是，MCP 接口只供大模型调用，而大模型每次都会动态读取使用规范，因此我们能够随时更改 MCP 服务器，不会有任何问题。

-- 史蒂夫·克劳斯，美国程序员

---

如果你向人们展示问题，又向他们展示解决方案，人们就会受到触动并采取行动。

-- 比尔·盖茨

---

最近，我在思考一个问题，如果 AI 能够将我们的语言翻译成可运行的代码，那么我们还需要编程语言吗？

-- 《语言无关的编程》
