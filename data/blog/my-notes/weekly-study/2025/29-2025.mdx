---
title: 2025-第二十九周
date: '2025-07-16'
tags: ['WEEKLY-2025']
draft: false
summary: ''
---

`该周报主要为各个地方内容的汇总整理`

<TOCInlineWithSticky toc={props.toc} />

## 技术

## 工具

### [jaaz](https://github.com/11cafe/jaaz)

AI 设计助手，Lovart 的本地替代方案。具备设计、编辑及生成图像、海报、故事板等功能的智能代理。

### [mcp-for-next.js](https://github.com/vercel-labs/mcp-for-next.js)

这是一个基于 Next.js 的 MCP 服务器示例项目，使用 Vercel 的 MCP 适配器，允许在 Next.js 项目中快速集成 MCP 服务器功能。项目包含配置说明、部署要求及示例客户端脚本。

- 🚀 **项目用途** - 示例 Next.js MCP 服务器，集成 Vercel 的 MCP 适配器，支持在指定路由部署 MCP 服务。
- 📂 **文件结构** - 包含应用路由、公共资源、脚本及配置文件（如`next.config.ts`、`package.json`等）。
- 🔧 **配置要求** - 使用 SSE 传输时需要 Redis（通过`process.env.REDIS_URL`配置），并需启用 Fluid 计算优化性能。
- ⏱️ **性能调整** - 建议在 Vercel Pro 或企业账户中调整`maxDuration`至 800 秒以适配长时运行。
- 🚀 **部署说明** - 提供直接部署 Next.js MCP 模板的指引。
- 💻 **示例客户端** - 包含测试脚本`scripts/test-client.mjs`，用于调用 MCP 服务端点。

### [opencode](https://github.com/opencode-ai/opencode)

OpenCode 是一个基于 Go 开发的终端 AI 助手，专为开发者设计，提供智能编码辅助功能。该项目现更名为 Charm，由原开发者 Kujtim Hoxha 继续维护，目前处于早期开发阶段，功能可能不稳定。支持多模型交互、会话管理、代码工具集成等，适合在终端环境中高效完成开发任务。

## 更新

## 设计

## AI

### [a2a-js](https://github.com/a2aproject/a2a-js)

Agent2Agent (A2A) 协议官方 JavaScript SDK

### [译：长上下文为何会失效](https://sorrycc.com/how-contexts-fail-and-how-to-fix-them)

本文探讨了大型语言模型中长上下文窗口（context window）带来的潜在问题，分析了四种常见的“上下文失效”模式（投毒、干扰、混淆、冲突），并指出这些失效对智能代理（agent）的负面影响。文章强调，单纯扩展上下文长度并不能提升模型表现，反而可能引发新的失效场景，最后预告了后续解决方案。

- 🧪 **上下文投毒** - 幻觉或错误信息进入上下文后会被反复引用，导致代理执着于错误目标（如 Gemini 玩《宝可梦》时因幻觉制定荒谬策略）。
- 🎯 **上下文干扰** - 上下文过长时，模型过度依赖历史记录而忽略训练知识（如 Gemini 2.5 在超 10 万 token 后重复旧动作而非制定新计划）。
- 🤯 **上下文混淆** - 无关内容污染响应质量（如伯克利实验显示模型调用无关工具，小模型在 46 个工具下完全失效）。
- ⚔️ **上下文冲突** - 新增信息与原有上下文矛盾（微软实验证明分阶段输入信息会导致模型得分暴跌 39%）。
- ⚠️ **代理的高风险性** - 代理因多源信息整合、连续工具调用等场景更易遭遇上下文失效。
- 🔮 **解决方案预告** - 动态加载工具、建立上下文隔离区等方法将后续探讨。

### [译：我是如何使用 LLM 辅助我写代码的](https://sorrycc.com/how-i-use-llms-to-write-code)

本文作者 Simon Willison 分享了他使用大语言模型（LLM）辅助编程的实践经验，强调了合理预期、上下文管理、测试代码等关键技巧，并通过实际案例展示了如何高效利用 LLM 提升开发速度和学习效率。

- 🎯 **设定合理预期**：LLM 本质是高级自动补全工具，需结合开发者技能使用，而非完全依赖。
- 📅 **考虑训练数据截止日期**：模型对库的熟悉度受限于训练数据时间，选择稳定且流行的库效果更好。
- 🗂️ **上下文为王**：LLM 的表现高度依赖对话上下文，可通过导入代码或文档优化结果。
- ❓ **询问选项**：在项目初期用 LLM 调研技术方案，快速验证可行性。
- ✍️ **明确指令**：像对待“数字实习生”一样，用详细需求描述生成代码（如函数签名 + 英文说明）。
- 🧪 **必须测试代码**：LLM 生成的代码需人工验证，这是开发者不可推卸的责任。
- 💬 **对话式迭代**：通过多次反馈修正结果（如“重构这段代码”“按时间排序”）。
- ⚙️ **使用代码运行工具**：如 ChatGPT Code Interpreter 或 Claude Artifacts，在沙箱中实时验证代码。
- 🎨 **Vibe-coding 学习法**：通过“凭感觉”快速实验探索模型能力边界。
- 🚀 **开发速度优势**：LLM 能实现原本因时间成本被放弃的项目，如半小时内完成版本说明页。
- 🔍 **放大专业知识**：LLM 效果与使用者的经验正相关，擅长回答代码库问题（如架构解析）。
- ⚠️ **随时接管**：遇到复杂问题（如 GitHub Actions 配置）时需人工干预。

### [译：Claude Code 中级指南](https://sorrycc.com/claude-code-intermediate-guide)

本文是一篇关于如何高效使用 **Claude Code** 的中级用户指南，作者 **Gatsby** 基于自身学习经验，总结了安装配置、精度优化、工作流技巧等实用方法，帮助用户快速提升 Claude Code 的使用效率。

- 🚀 **安装与初始化**

  - 通过 `npm` 安装 Claude Code，启动会话后优先用 `summarize this project` 让 Claude 理解项目上下文。
  - 使用 `/init` 创建 `CLAUDE.md` 文件存储项目摘要，确保跨会话记忆。

- 📝 **持久化上下文**

  - 通过示例提示（如项目功能、技术栈、目录结构等）填充 `CLAUDE.md`，避免每次会话重置上下文。

- ⚠️ **避免大段输入**

  - 将长文本指令写入文件后让 Claude 读取，而非直接粘贴到提示框，以提高回答质量。

- 💡 **深度思考模式**

  - 使用 `ultrathink` 等关键词提升 Claude 的思考深度（消耗更多 token），适合复杂问题。

- 🔍 **分阶段工作流**

  - 按 **探索→规划→编码→提交**（Explore, Plan, Code, Commit）顺序下达指令，减少偏差。

- ✅ **测试驱动开发（TDD）**

  - 先让 Claude 编写测试代码，再实现功能，最后通过测试，确保代码可靠性。

- ♻️ **会话管理**

  - 使用 `/clear` 重置混乱的会话，或通过 `claude --resume` 恢复历史会话。

- 🔔 **任务通知设置**

  - 配置任务完成提醒（如终端铃声），避免长时间等待无反馈。

- 📊 **用量监控**
  - 运行 `npx ccusage` 查看每日 token 消耗和费用估算，优化使用效率。

### [译：我如何 Vibe Coding](https://sorrycc.com/how-i-vibe-coding)

本文作者 Xuanwo 分享了他作为开源 Rust 工程师如何将 AI 工具（如 Claude Code）融入日常工作流的经验。他强调了 AI 在代码重构、工具使用和任务规划中的优势，但也指出其局限性，需结合人工审查和明确指导。文章还提供了具体工具配置、工作流设计及实用建议，适合希望高效利用 AI 辅助编程的开发者参考。

- 🧑💻 **作者背景**

  - 开源 Rust 工程师，工作环境开放，允许 LLM 直接访问代码上下文。
  - Rust 语言特性（如优秀工具链和文本化代码）与 AI 协作高度适配。

- 🛠️ **工具集**

  - 主要使用 **Zed 编辑器** 和 **Claude Code**（通过自定义 Docker 容器运行）。
  - 配置别名 `claudex` 快速启动 Claude，并挂载代码、配置和笔记目录。

- 🤖 **AI 使用理念**

  - 将 LLM 视为初级开发者：擅长结构化任务，但需人工提供上下文、方向和审查。
  - 仅让 AI 编写可掌控的代码（如重构已有模块），避免完全依赖其设计新组件。

- ⏳ **工作流设计**

  - 每日分为 5 小时区块（匹配 Claude 使用限制）：上午规划（用 Obsidian 记录笔记），下午编码与审查。
  - 通过 `git worktree` 启动多实例协作，依赖 Rust 工具链（`cargo check/test`）自动化验证代码。

- 🚨 **关键注意事项**

  - 警惕 AI 过度自信（如虚构 API），需人工把控公共 API 和复杂逻辑。
  - 反对盲目配置 MCP 服务器，优先利用本地工具链（如 `gh CLI`）。

- 💡 **实用建议**
  - **Claude 4** 是目前最适合编程的模型（强于规划和工具使用）。
  - 将 AI 融入现有工作流，而非颠覆习惯（如不强制切换 IDE）。

### [context-engineering-intro](https://github.com/coleam00/context-engineering-intro)

介绍了**上下文工程（Context Engineering）**的模板和使用指南，这是一种为 AI 编程助手提供全面上下文信息的系统化方法，比传统提示工程（Prompt Engineering）和随意编码（Vibe Coding）更高效。文章详细说明了模板结构、操作步骤、最佳实践，并强调了通过示例和文档提升 AI 实现复杂功能的能力。

- 🚀 **快速开始**
  - 克隆模板仓库，设置项目规则，添加代码示例，创建初始需求文件（`INITIAL.md`），生成并执行产品需求提示（PRP）。
- 📖 **什么是上下文工程？**
  - 从传统提示工程的“便签式”指令升级为包含文档、示例、规则和验证的完整系统，减少 AI 错误并确保一致性。
- 🏗️ **模板结构**
  - 包含全局规则文件（`CLAUDE.md`）、示例目录、PRP 生成与执行命令，以及需求描述模板（`INITIAL.md`）。
- 🔧 **分步指南**
  1. 设置全局规则（项目规范、测试要求等）；
  2. 编写详细需求文件；
  3. 生成 PRP（含实现步骤和验证）；
  4. 执行 PRP 自动实现功能。
- ✍️ **编写有效需求文件**
  - 需明确功能描述、示例引用、相关文档链接及其他注意事项（如性能要求、常见陷阱）。
- 🔄 **PRP 工作流程**
  - 生成阶段：分析代码库、收集文档、创建详细蓝图；
  - 执行阶段：按计划实现、验证测试、迭代修复。
- 📂 **示例的运用**
  - 在`examples/`目录中提供代码结构、测试模式、集成方案等示例，显著提升 AI 实现质量。
- ✅ **最佳实践**
  - 明确需求、丰富示例、添加验证关卡、定制项目规则（`CLAUDE.md`），并充分利用文档资源。

## 其他
