---
title: 2026-第一周
date: '2026-01-05'
tags: ['WEEKLY-2026']
draft: false
summary: ''
---

`该周报主要为各个地方内容的汇总整理`

<TOCInlineWithSticky toc={props.toc} />

## 技术

### [仅用 200 行 JavaScript 实现 JSON 流式传输](https://krasimirtsonev.com/blog/article/streaming-json-in-just-200-lines-of-javascript)

渐进式 JSON 流式传输的核心思想是将可用的 JSON 数据部分立即发送，而不是等待整个 JSON 结构准备就绪。这尤其适用于大型数据集或实时生成数据的场景。对于尚未就绪的数据，可以发送占位符，客户端在后续收到实际数据时再进行替换。

- 🚀 **流式传输优势**：通过立即发送可用数据部分，减少等待时间，提升大型数据集或实时生成数据场景下的响应速度。
- 🧩 **占位符机制**：对于尚未就绪的数据（如数据库查询结果），先发送唯一标识的占位符（如`"_$1"`），待数据就绪后再以独立区块发送实际内容。
- 🛠️ **服务器实现**：使用`application/x-ndjson`内容类型和`Transfer-Encoding: chunked`头部，通过递归遍历数据对象，将 Promise 替换为占位符并注册至队列，待解析后发送对应区块。
- 🌐 **客户端处理**：利用 Fetch API 读取流式响应，将接收到的占位符转换为 Promise，并在收到对应数据区块时解析替换，最终整合完整数据。
- 📦 **开源工具**：提供了 NPM 库 Streamson，简化服务器与客户端的实现，仅需约 200 行代码即可在两端实现完整的流式 JSON 处理功能。

### [一致性的代价：避免设计系统瓶颈 | Omid Farhang](https://omid.dev/2025/12/25/cost-of-consistency-design-systems/)

本文探讨了设计系统在规模化过程中可能引发的“一致性成本”问题，并分享了避免系统僵化和抽象化陷阱的实践经验。

- 🚧 **设计系统的“僵化陷阱”**：随着依赖系统的应用增多，即使是微小的组件变更也可能引发冗长的审批、实施和迁移流程，反而阻碍创新。
- 💸 **抽象化带来的“税收”**：高度封装的组件虽简化开发，但当需求超出抽象范围时，开发者需花费额外时间“对抗”系统，效率反而降低。
- 🏛️ **联邦式治理模型**：采用去中心化的内部开源模式，核心设计元素严格管控，同时允许团队根据需求自定义组件，平衡一致性与灵活性。
- 🚫 **学会对系统说“不”**：在实验性功能、一次性营销页面或内部工具等场景中，应避免过度依赖设计系统，优先考虑开发效率。
- 🧑‍💻 **系统服务于人**：设计系统是工具而非教条，其最终目标是提升开发效率与产品体验，若成为负担则需调整治理策略而非仅修改代码。

### [2026 年定义 Web 开发的八大趋势 - LogRocket 博客](https://blog.logrocket.com/8-trends-web-dev-2026/)

本文展望了 2026 年 Web 开发的八大趋势，强调 AI 工具、元框架、TanStack 生态、TypeScript 与边缘计算等技术的融合将重塑开发流程，使开发者更专注于架构与用户体验，而非底层实现。

- 🤖 AI 优先开发成为核心，开发者转向架构师角色，AI 代理负责从设计到代码的生成与优化
- 🏗️ 元框架（如 Next.js、Nuxt）成为项目标准入口，集成路由、数据获取和 API 层，降低配置成本
- 🧩 TanStack 生态主导前端逻辑层，其模块化工具（如 Query、Table）推动应用可移植性与可维护性
- 🔒 TypeScript 与服务器函数结合，实现端到端类型安全，简化后端开发，促进前后端融合
- ⚙️ React 编译器普及，自动处理性能优化，减少手动记忆化代码，提升开发体验
- 🌍 边缘计算成为默认部署目标，降低延迟并简化扩展，框架特性与边缘运行环境深度集成
- 🎨 CSS 演进为实用类与原生特性混合模式，设计系统基于 CSS 变量与层叠机制，提升样式可维护性
- 🛡️ React 应用安全性增强，框架引入更严格的默认配置与静态分析，以应对扩大的攻击面

### [译：以推理速度交付](https://sorrycc.com/shipping-at-inference-speed)

本文概述了作者自五月以来使用 AI 编程助手（特别是 GPT-5 Codex）进行“氛围编码”的体验演进。他强调了模型能力的飞速提升如何极大地加速了软件开发流程，使其交付速度达到前所未有的水平。作者分享了他对 Codex 与 Opus 模型差异的见解，介绍了自建的 Oracle 工具，并以 VibeTunnel 等项目为例说明了当前模型的强大。此外，他详细阐述了自己高效的工作流、项目管理和配置心得，核心在于迭代开发、为 AI 设计代码库以及保持简单直接的操作方式。

- 🚀 **开发速度革命**：自五月以来，AI 编程模型（尤其是 GPT-5 Codex）的能力飞跃，使代码生成成为基本预期，极大地提升了软件交付速度。
- 🤖 **模型信任与工作方式转变**：与 AI 智能体深入协作后，能准确预估任务耗时；GPT-5 Codex 因其在编码前深入“阅读”代码文件的习惯，在大型重构和功能开发上比更“急切”的 Opus 更可靠、产出质量更高。
- 🔧 **工具与工作流优化**：作者构建了 Oracle CLI 工具，让智能体在卡顿时能自动调用更强大的 GPT-5 Pro 进行深度研究；但 GPT-5.2 发布后，对 Oracle 的依赖已大幅减少。
- 🛠️ **技术选型与生态**：根据项目类型选择语言（TypeScript for Web, Go for CLI, Swift for macOS/UI），并指出Go因其简单的类型系统而特别受AI擅长处理。
- 📁 **项目与上下文管理**：采用迭代式开发，很少预先完整规划；通过维护项目文档（docs 文件夹）和全局 AGENTS 文件来为 AI 提供上下文，而非依赖会话历史；偏好线性提交到 main 分支，而非复杂的分支策略。
- ⚙️ **配置与偏好**：主要使用`gpt-5.2-codex high`模型，并分享了 Codex 配置（如提高`tool_output_token_limit`以允许模型读取更多内容），强调保持简单（KISS 原则）。
- 💡 **当前挑战与焦点**：选择正确的依赖、框架和系统设计决策仍需投入相当多的时间；目前的个人重点项目是 Clawdis，一个拥有广泛设备和控制权限的 AI 助手。
- 🌐 **多设备与自动化**：通常在多台 Mac 上工作，通过 git 同步；广泛自动化各种任务（如域名注册、前端编写），并将 AI 智能体集成到日常网络和设备管理中。
- 🎯 **开发哲学**：始终从模型和 CLI 开始构建新想法；认为代码库应为 AI 高效工作而设计，而非仅为人导航；发现并推广新模式后，会让 AI 在所有相关项目中实施更新。

### [使用 Agent 编码的最佳实践](https://cursor.com/cn/blog/agent-best-practices)

本文是一份关于如何使用 Cursor Agent 进行高效编码的详细指南。它介绍了 Agent 的基本工作原理、核心使用技巧以及最佳实践，旨在帮助开发者将 AI Agent 作为强大的协作工具，融入软件开发流程。

- 🤖 **理解 Agent 的运作基础**：Agent 的有效性建立在指令（Instructions）、工具（Tools）和用户消息（User messages）三大组件之上。Cursor 的 Agent 框架会为不同模型优化这些组件，让开发者能专注于构建软件本身。
- 📝 **编码前先规划**：最大的改变是在写代码前先使用 **Plan 模式**（Shift+Tab）。Agent 会分析代码库、提出问题并制定详细计划，这能明确目标并提升实现质量。计划可保存以供团队复用。
- 🔄 **灵活管理对话与上下文**：为不同任务开启新对话，避免上下文过长导致 Agent 分心。利用 `@Branch`、`@Past Chats` 等功能让 Agent 自行获取所需上下文，无需在提示中手动标记所有文件。
- ⚙️ **用 Rules 和 Skills 扩展 Agent**：**Rules**（在 `.cursor/rules/` 中定义）提供静态的项目规则和风格指南；**Skills**（动态加载）则提供可复用的工作流、钩子脚本和领域知识，能创建长时间运行、目标导向的 Agent 循环。
- 🖼️ **利用多模态能力**：Agent 可直接处理图片，例如将设计稿截图转换为代码，或对错误界面截图进行可视化调试，这比文字描述更高效。
- 🧪 **实施测试驱动开发等高效工作流**：明确要求 Agent 先编写失败测试，再实现功能并迭代至通过。Agent 也能帮助理解新代码库、自动化 Git 操作（如创建 PR）、进行代码审查和生成架构图。
- ⚡ **并行运行与云端委托**：可以并行运行多个 Agent（甚至不同模型）在隔离的 worktree 中解决同一问题，并比较结果。可将琐碎任务（如修复、重构、写测试）委托给**云端 Agent**，它们会在后台完成并提交 PR。
- 🐛 **使用 Debug Mode 解决棘手问题**：对于复杂 Bug，该模式会生成假设、插入日志、收集运行时数据并基于证据进行精准修复，尤其适用于可复现但原因不明的问题。
- 🛠️ **打造个性化高效工作流**：成功的关键在于：编写具体、可验证的提示；从简单配置开始，逐步迭代优化；认真审查 AI 生成的代码；将 Agent 视为有能力的协作者，要求其解释和规划。

## 工具

### [Markdown UI - 交互式编辑器与演示](https://markdown-ui.com/)

Markdown UI 是一个将静态 Markdown 文档转换为交互式界面的工具，它通过一种简单的领域特定语言（DSL）在 Markdown 代码块中定义交互组件，并能在任何前端框架中渲染为可交互的部件，同时保持对 AI 生成和人类编写的良好支持。

- ✨ **核心功能**：将静态 Markdown 文档瞬间转换为可交互的 UI 部件，如按钮、下拉菜单、表单、图表和测验。
- 🤖 **AI 友好**：其 DSL 语法易于被大型语言模型（LLM）理解和生成，便于创建交互式流程并收集反馈。
- 📄 **无锁定与兼容**：基于纯文本规范，可与任何 Markdown 解析器和 UI 框架配合使用，在不支持的环境中仍可正常阅读。
- ⚡ **快速集成**：提供 React、Svelte、Vue 等主流框架的渲染包，以及针对 Marked.js 的解析器扩展，可在 30 秒内快速上手。
- 🛠️ **丰富的部件类型**：支持按钮组、选择器、滑块、表单、多种图表以及带有评分反馈功能的测验和题目。
- 📚 **清晰的语法规范**：提供了详细的 DSL 语法参考，包括部件类型定义、引用规则和大量示例，便于编写和集成。

### [monaco-loader](https://github.com/suren-atoyan/monaco-loader)

该库是一个用于在浏览器中轻松设置 Monaco 编辑器的工具，它通过加载器脚本配置和加载 Monaco 资源，无需依赖 webpack 等模块打包器的配置文件，简化了集成过程。

- 🛠️ **简化配置**：无需 webpack 等打包器的复杂配置，即可将 Monaco 编辑器集成到浏览器中。
- 📦 **独立工具**：源自 `@monaco-editor/react` 的初始化工具，现已发展为独立库，支持 React/Vue/Angular 等框架。
- 🔧 **加载器机制**：基于 Monaco 官方加载器脚本，提供配置和加载的封装 API。
- ⚙️ **灵活配置**：支持自定义 Monaco 资源路径（如本地文件或 npm 包）和语言本地化设置。
- ⚡ **初始化控制**：提供 `.init()` 方法返回可取消的 Promise，便于管理 Monaco 实例加载。
- 🖥️ **环境适配**：针对 Electron 用户提供路径配置方案，解决外部资源加载问题。
- 🌐 **服务端渲染**：为 Next.js 等框架优化，避免浏览器环境依赖导致的服务器端问题。
- 📚 **类型支持**：需单独安装 `monaco-editor` 包以获得 TypeScript 类型定义。

### [Open-AutoGLM](https://github.com/zai-org/Open-AutoGLM)

Open-AutoGLM 是一个基于 AutoGLM 模型构建的手机端智能助理框架，能够通过多模态理解手机屏幕内容并自动化执行用户指令。它支持 Android、HarmonyOS 和 iOS 设备，通过 ADB/HDC 控制设备，结合视觉语言模型进行屏幕感知与操作规划，实现"用自然语言控制手机"的功能。项目提供模型部署指南、环境配置说明及多种使用方式，适用于研究、学习和自动化任务场景。

- 📱 **项目定位**：基于 AutoGLM 的手机端智能助理框架，支持通过自然语言指令自动化操作手机。
- 🔗 **设备支持**：兼容 Android、HarmonyOS 和 iOS 系统，需配置 ADB（Android）或 HDC（鸿蒙）等调试工具。
- 🧠 **核心能力**：利用多模态模型理解屏幕内容，自动规划并执行点击、输入、滑动等操作以完成任务。
- ⚙️ **环境准备**：需要 Python 3.10+、开发者模式、USB 调试权限，Android 设备需额外安装 ADB Keyboard 输入法。
- 🌐 **模型服务**：可选择自行部署模型（通过 vLLM/SGLang）或使用第三方服务（如智谱 BigModel、ModelScope）。
- 🚀 **使用方式**：支持命令行交互、Python API 调用，并提供远程调试（WiFi 连接）和多设备管理功能。
- 📂 **应用覆盖**：支持 50+ 款 Android 应用和 60+ 款鸿蒙原生应用，涵盖社交、购物、娱乐等常见类别。
- ⚠️ **注意事项**：仅供研究学习使用，需遵守使用条款；部署时需注意设备连接、权限配置及模型服务可用性。

## 更新

### [在 Node.js 脚本中自动加载.env 文件 | Stefan Judis Web 开发](https://www.stefanjudis.com/today-i-learned/load-env-files-in-node-js-scripts/)

Node.js 现已原生支持加载.env 文件，无需依赖第三方库如 dotenv，提供了命令行标志和脚本内方法两种方式。

- 🚀 Node.js 新增原生支持加载.env 文件，减少对 dotenv 等第三方库的依赖
- ⚙️ 可通过命令行标志`--env-file`和`--env-file-if-exists`或脚本内`loadEnvFile()`方法加载环境变量
- 📁 `loadEnvFile()`方法默认加载当前目录的.env 文件，也支持自定义文件路径
- ⚠️ 需注意`loadEnvFile()`在.env 文件不存在时会抛出错误，生产环境中建议使用错误处理包装
- 💡 作者分享了一个安全加载工具函数，可忽略文件不存在的错误，适用于生产环境
- 📅 该功能自 Node.js v24 起标记为稳定，体现了 Node.js 持续集成用户常用特性的发展趋势

## 设计

## AI

## 其他

Make it work (Al) .
Make it fast (also Al) .
Make it beautiful (still human) .

让它运转起来（人工智能）。
速度要快（也需要人工智能）。
让它变得美丽（但仍然是人性化的）。

--- DHH

---

程序员对待 AI 有两种态度：一种以结果为导向，渴望通过 AI 更快拿到结果；另一种以过程为导向，他们从工程本身获得意义，对于被剥夺这种体验感到不满。

-- Ben Werdmuller
